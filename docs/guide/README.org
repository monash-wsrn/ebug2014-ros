#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t
#+TITLE: Ahmet's Robots
#+DATE: <2017-09-06 mer>
#+AUTHOR: Nicola Roberto Zema
#+EMAIL: nicola.zema@unirc.it
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.2.1 (Org mode 9.0.10)
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS:
#+LATEX_HEADER:
#+LATEX_HEADER_EXTRA:
#+DESCRIPTION:
#+KEYWORDS:
#+SUBTITLE:
#+LATEX_COMPILER: pdflatex
# #+DATE: \today

# #+begin_src css
# .sponsors .figure {
#     display: inline;
# }

# .sponsors .figure p {
#     display: inline;
# }

# .sponsors .figure img {
#     vertical-align: middle;
# }
# #+end_src

# If you simply want a vertical list of images, you can simply override
# the setting for .figure p:

# #+begin_src css
# .sponsors .figure p {
#     text-align: left;
# }

#+OPTIONS: html-link-use-abs-url:nil html-postamble:auto
#+OPTIONS: html-preamble:t html-scripts:t html-style:t
#+OPTIONS: html5-fancy:nil tex:t
#+HTML_DOCTYPE: xhtml-strict
#+HTML_CONTAINER: div
#+DESCRIPTION:
#+KEYWORDS:
#+HTML_LINK_HOME:
#+HTML_LINK_UP:
#+HTML_MATHJAX:
#+HTML_HEAD:

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/suse_todo.css" />
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="css/aligner.css" /> 
#+SUBTITLE:
#+INFOJS_OPT:
#+CREATOR: <a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.2.1 (<a href="http://orgmode.org">Org</a> mode 9.0.10)
#+LATEX_HEADER:


# specifying the beamer startup gives access to a number of
# keybindings which make configuring individual slides and components
# of slides easier.  See, for instance, C-c C-b on a frame headline.

#+STARTUP: beamer

#+STARTUP: oddeven

# we tell the exporter to use a specific LaTeX document class, as
# defined in org-latex-classes.  By default, this does not include a
# beamer entry so this needs to be defined in your configuration (see
# the tutorial).
# #+LaTeX_CLASS: beamer

# #+LaTeX_CLASS_OPTIONS: [bigger]
# #+LaTeX_CLASS_OPTIONS: [c]
# #+LATEX_HEADER: \usepackage{tikz}

# # Beamer supports alternate themes.  Choose your favourite 
# # #+BEAMER_THEME: Frankfurt
# # #+BEAMER_COLOR_THEME: crane
# #+BEAMER_THEME: bjeldbak
# # #+BEAMER_THEME: Amsterdam
# # #+BEAMER_THEME: Frankfurt
# # #+BEAMER_THEME: PraterStreet
# # #+BEAMER_COLOR_THEME: beaver

# # #+BEAMER_OUTER_THEME: smoothbar
# # #+BEAMER_INNER_THEME: circles
# # #+BEAMER_COLOR_THEME: wolverine

# # #+BEAMER_THEME: s4ndm4n

# the beamer exporter expects to be told which level of headlines
# defines the frames.  We use the first level headlines for sections
# and the second (hence H:2) for frames.
#+OPTIONS:   H:2 toc:t

# the following allow us to selectively choose headlines to export or not
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport

# for a column view of options and configurations for the individual
# frames

#+COLUMNS: %20ITEM %13BEAMER_env(Env) %6BEAMER_envargs(Args) %4BEAMER_col(Col) %7BEAMER_extra(Extra)

* =ebug_swarm_control=

** Instructions

   Just drop the =ebug_swarm_control= folder into
   =/home/<username>/catkin_ws/src= and issue a ~catkin_make~ as per
   manuals/tutorials.

   I have made also a launch file.

   Jeez!

** Mail
Original mail from the man.
#+begin_example
   Hi Nicola,
   
   Can we build a ROS structure consisting of the following blocks:

1. control_node
2. localization_node
3. planning_node
4. visualization_node
   
They will basically do nothing but exchange information through the
ROS provided (blue marked in the attached diagram) mechanisms (I
forgot the name of this whiteboard?).

If you can write a simple program in the planning_node that will
generate an initial position x,y 0 < x < 640 and 0 < y < 480 (blob
camera resolution).

control_node will read it and write it for localization_node to read.

Then the localization_node will read and write it for
visualization_node and planning_node to read.

visualization_node will have an openCV code to display a circle in a
rectangular window representing the current position of the "robot" as
a simple circle.

planning_node will read the position and generate a next position to
model a random walk of the robot. This cycle will keep going
indefinitely.

I think this will be a good starting point for us.
#+end_example


** Attached Material

   #+CAPTION: Original Ahmet Idea
   #+LABEL: fig:ahmetPlan
   #+ATTR_HTML: style="display:inline;margin:10px;"
   [[file:./material/oldScreenshot.png]]
   # file:./material/eBugSwarm.pdf


   # [[./material/eBug Swarm.pdf][]]

** DONE Action Plan

*** DONE Create nodes
    CLOSED: [2017-09-18 lun 01:02]

*** DONE Setup makefiles and xml
    CLOSED: [2017-09-18 lun 01:02]

*** DONE =planning_node=
    CLOSED: [2017-09-18 lun 02:10]
#+BEGIN_EXAMPLE
the planning_node that will
generate an initial position x,y 0 < x < 640 and 0 < y < 480 (blob
camera resolution).
#+END_EXAMPLE
**** DONE basic data generation
     CLOSED: [2017-09-18 lun 02:10]
     - It is an image ~640x480~;
     - It is a =sensor_msgs/Image Message=
     - File: =sensor_msgs/Image.msg=
     - Things to take into consideration:
     - Header header (see [[Info]])
       - WTF?!?!
     - ~uint32 height         # image height, that is, number of rows~
       - Can Fake it
     - ~uint32 width          # image width, that is, number of columns~
       - Can Fake it
     - ~string encoding       # Encoding of pixels -- channel meaning, ordering, size~
       - Can Fake it
     - ~uint8 is_bigendian    # is this data bigendian?~
       - Can Fake
     - ~uint32 step           # Full row length in bytes~
       - Can Fake
     - ~uint8[] data          # actual matrix data, size is (step * rows)~
       - Can Fake:
	 - Fill it with 1s
     - *ROS TAKES CARE OF ALL DEFAULTS*
***** How to handle it 
      Send it as a message on a dedicated topic.
***** Info
#+BEGIN_EXAMPLE
# This message contains an uncompressed image
# (0, 0) is at top-left corner of image
#

Header header        # Header timestamp should be acquisition time of image
                     # Header frame_id should be optical frame of camera
                     # origin of frame should be optical center of cameara
                     # +x should point to the right in the image
                     # +y should point down in the image
                     # +z should point into to plane of the image
                     # If the frame_id here and the frame_id of the CameraInfo
                     # message associated with the image conflict
                     # the behavior is undefined

uint32 height         # image height, that is, number of rows
uint32 width          # image width, that is, number of columns

# The legal values for encoding are in file src/image_encodings.cpp
# If you want to standardize a new string format, join
# ros-users@lists.sourceforge.net and send an email proposing a new encoding.

string encoding       # Encoding of pixels -- channel meaning, ordering, size
                      # taken from the list of strings in include/sensor_msgs/image_encodings.h

uint8 is_bigendian    # is this data bigendian?
uint32 step           # Full row length in bytes
uint8[] data          # actual matrix data, size is (step * rows)
#+END_EXAMPLE
*** DONE =control_node=
    CLOSED: [2017-09-18 lun 02:27]
#+BEGIN_EXAMPLE
control_node will read it and write it for localization_node to read.
#+END_EXAMPLE
**** DONE Message Transport
     CLOSED: [2017-09-18 lun 02:27]
      - Read the image from [[=planning_node=]]
      - Rebroadcast it.
*** DONE =localization_node=
    CLOSED: [2017-09-18 lun 02:27]
#+BEGIN_EXAMPLE
the localization_node will read and write it for
visualization_node and planning_node to read.
#+END_EXAMPLE
**** DONE Message Transport
     CLOSED: [2017-09-18 lun 02:27]
     Same as [[=control_node=]]
*** DONE =visualization_node=
    CLOSED: [2017-09-18 lun 02:27]
#+BEGIN_EXAMPLE
visualization_node will have an openCV code to display a circle in a
rectangular window representing the current position of the "robot" as
a simple circle.
#+END_EXAMPLE
**** DONE Data Endpoint
     CLOSED: [2017-09-18 lun 02:27]
     Just print out some stuff.

** TODO Follow-up [0/2]
   - [ ] set proper names on the topics [0/4]
     - [ ] blobs :: control -> localization
     - [ ] poses :: localization -> planning
     - [ ] commands :: planning -> control
     - [ ] trajectories :: traj-calc -> planning
   - [ ] each node as a separate package as in Figure [[fig:newnodestructure]] [0/4]
     - [ ] control
     - [ ] localization
     - [ ] planning
     - [ ] traj-calc
   #+CAPTION: Ahmet's New Node Structure
   #+LABEL: fig:newnodestructure
   #+ATTR_HTML: style="display:inline;margin:10px;"
   [[file:./material/newnodes.png]]

   #+CAPTION: Ahmet's Updated Node Structure
   #+LABEL: fig:updatednodestructure
   #+ATTR_HTML: style="display:inline;margin:10px;"
   [[file:material/ros-architecture.png][file:~/workspace/ebug2014-ros/docs/guide/material/ros-architecture.png]]

* Image Comparison
  :PROPERTIES:
  :HTML_CONTAINER_CLASS: sponsors
  :END:
   #+ATTR_HTML: :height 500px
   [[./material/newnodes.png]]
   #+ATTR_HTML: :height 500xp
   [[./material/oldScreenshot.png]]
